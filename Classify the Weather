import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import LabelEncoder
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, classification_report

# Load data
daily_data = pd.read_csv('/content/daily_data.csv')

# Clean data
daily_data['day_id'] = daily_data['day_id'].astype(str).str.replace('D', '').astype(int)
daily_data['city_id'] = daily_data['city_id'].astype(str).str.replace('C', '').astype(int)

# Handle missing values
daily_data['day_id'] = pd.to_numeric(daily_data['day_id'], errors='coerce')
daily_data['city_id'] = pd.to_numeric(daily_data['city_id'], errors='coerce')

# Drop rows where condition_text is missing
labeled_data = daily_data.dropna(subset=['condition_text'])

# Encode condition_text
label_encoder = LabelEncoder()
labeled_data['condition_text_encoded'] = label_encoder.fit_transform(labeled_data['condition_text'])

# Extract features and target
features = labeled_data[['temperature_celsius', 'wind_kph', 'wind_degree', 'pressure_mb', 'precip_mm',
                         'humidity', 'cloud', 'feels_like_celsius', 'visibility_km', 'uv_index',
                         'gust_kph', 'air_quality_us-epa-index']]
target = labeled_data['condition_text_encoded']

# Handle any other missing values in features if necessary (e.g., fillna with mean)
features.fillna(features.mean(), inplace=True)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42, stratify=target)

# Define XGBoost model with parameter grid for hyperparameter tuning
xgb_model = XGBClassifier(objective='multi:softmax', num_class=len(label_encoder.classes_), random_state=42, n_jobs=-1)

# Parameter grid for GridSearchCV
param_grid = {
    'n_estimators': [100, 200, 300],
    'learning_rate': [0.01, 0.05, 0.1],
    'max_depth': [5, 7, 9],
    'subsample': [0.8, 1.0],
    'colsample_bytree': [0.8, 1.0],
    'gamma': [0, 0.1, 0.2],
    'min_child_weight': [1, 5, 10]
}

# Grid search for best parameters
grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5, scoring='accuracy', verbose=1, n_jobs=-1)
grid_search.fit(X_train, y_train)

# Best model from grid search
best_model = grid_search.best_estimator_

# Evaluate on test set
y_pred = best_model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy:.4f}')
print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))

# Load full dataset for final prediction
full_data = pd.read_csv('/content/daily_data.csv')

# Prepare features for prediction on full dataset
full_features = full_data[['temperature_celsius', 'wind_kph', 'wind_degree', 'pressure_mb', 'precip_mm',
                           'humidity', 'cloud', 'feels_like_celsius', 'visibility_km', 'uv_index',
                           'gust_kph', 'air_quality_us-epa-index']]

# Handle missing values in full dataset
full_features.fillna(full_features.mean(), inplace=True)

# Predict missing values for condition_text in full dataset
missing_condition_indices = full_data['condition_text'].isnull()
full_data.loc[missing_condition_indices, 'condition_text'] = label_encoder.inverse_transform(best_model.predict(full_features[missing_condition_indices]))

# Prepare submission file
submission = full_data[['day_id', 'condition_text']]
submission.to_csv('/content/submission.csv', index=False)
